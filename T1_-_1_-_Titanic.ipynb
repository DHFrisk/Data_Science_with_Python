{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "charged-quick",
   "metadata": {},
   "source": [
    "# Carga de datos con read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "failing-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "operational-newark",
   "metadata": {},
   "outputs": [],
   "source": [
    "mainpath= \"/home/not_admin/Documents/Courses/Data_Science_Python/My_Project/datasets/\"\n",
    "filename= \"titanic/titanic3.csv\"\n",
    "fullpath= mainpath+filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "located-florida",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv(fullpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "smoking-annotation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
       "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
       "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
       "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "       age  sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
       "0  29.0000      0      0   24160  211.3375       B5        S    2    NaN   \n",
       "1   0.9167      1      2  113781  151.5500  C22 C26        S   11    NaN   \n",
       "2   2.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "3  30.0000      1      2  113781  151.5500  C22 C26        S  NaN  135.0   \n",
       "4  25.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-macedonia",
   "metadata": {},
   "source": [
    "Ejemplo de parametros principales con read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accepting-washer",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/rypyvast/Documents/Courses/Data_Science_Python/My_Project/datasets/titanic/titanic3.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fb3359a891c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m data2= pd.read_csv(filepath_or_buffer= \"/home/rypyvast/Documents/Courses/Data_Science_Python/My_Project/datasets/titanic/titanic3.csv\",\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hola\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"que\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tal\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"como\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"estas\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gusto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"en\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"saludarte\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SKE\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"REEE\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"EEEE\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"EEEEEEEE\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"EEEEE\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                    \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         index_col= None, skip_blank_lines= False, na_filter= False)\n\u001b[1;32m      5\u001b[0m \u001b[0mdata2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/rypyvast/Documents/Courses/Data_Science_Python/My_Project/datasets/titanic/titanic3.csv'"
     ]
    }
   ],
   "source": [
    "data2= pd.read_csv(filepath_or_buffer= \"/home/rypyvast/Documents/Courses/Data_Science_Python/My_Project/datasets/titanic/titanic3.csv\",\n",
    "        sep= \",\", dtype={\"a\":np.int32, \"b\":np.float64}, header=0, names=[\"hola\", \"que\", \"tal\", \"como\", \"estas\", \"gusto\", \"en\", \"saludarte\", \"SKE\", \"REEE\", \"EEEE\", \"EEEEEEEE\", \"EEEEE\"],\n",
    "                   skiprows= 11,\n",
    "        index_col= None, skip_blank_lines= False, na_filter= False)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-flight",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aunque sea un .txt técnicamente cumple ya que está separado por comas\n",
    "data3= pd.read_csv(mainpath+\"customer-churn-model/Customer Churn Model.txt\")\n",
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-spirituality",
   "metadata": {},
   "outputs": [],
   "source": [
    "#para ver el nombres de las columnas\n",
    "data3.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#para reetiquetar los nombres de las columnas del dataset\n",
    "dataCols= pd.read_csv(mainpath+\"customer-churn-model/Customer Churn Columns.csv\")\n",
    "dataColsList= dataCols[\"Column_Names\"].tolist()\n",
    "print(dataCols)\n",
    "print(dataColsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3= pd.read_csv(mainpath+\"customer-churn-model/Customer Churn Model.txt\", header=None, names=dataColsList)\n",
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-democracy",
   "metadata": {},
   "source": [
    "### Carga de datos a través de la función open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AQUI SE HACE A PATITA PARA NO SOBRECARGAR LA MEMORIA CON PANDAS(PANDAS LO HACE TODO DE UN TIRÓN)\n",
    "data4= open(mainpath + \"customer-churn-model/Customer Churn Model.txt\", \"r\")\n",
    "cols= data4.readline().strip().split(\",\")\n",
    "nCols= len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-treat",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter= 0\n",
    "mainDict= {}\n",
    "for col in cols:\n",
    "    mainDict[col]= []\n",
    "\n",
    "mainDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in data4:\n",
    "    values= row.strip().split(\",\")\n",
    "    for i in range(len(cols)):\n",
    "        mainDict[cols[i]].append(values[i])\n",
    "    counter+=1\n",
    "print(\"el dataset tiene %d columnas y %d filas\"% (nCols, counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-homework",
   "metadata": {},
   "source": [
    "Convertir el dataset hecho manualmente a un dataframe de pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.DataFrame(mainDict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-instrument",
   "metadata": {},
   "source": [
    "## Lectura y escritura de ficheros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file= mainpath + \"customer-churn-model/Customer Churn Model.txt\"\n",
    "output_file= mainpath + \"customer-churn-model/Tab Customer Churn Model.txt\"\n",
    "with open(input_file, \"r\") as infile1:\n",
    "    with open(output_file, \"w\") as outfile1:\n",
    "        for i in infile1:\n",
    "            fields= i.strip().split(\",\")\n",
    "            outfile1.write(\"\\t\".join(fields)+\"\\n\") #PARA ESCRIBIR LOS CAMPOS SEPARADOS POR UN '\\T'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= pd.read_csv(output_file, sep=\"\\t\")\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-float",
   "metadata": {},
   "source": [
    "## Leer datos desde una URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "upset-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "medals_url= 'http://winterolympicsmedals.com/medals.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fifteen-mississippi",
   "metadata": {},
   "outputs": [],
   "source": [
    "medals_data= pd.read_csv(medals_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "anticipated-mississippi",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>City</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Discipline</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Event</th>\n",
       "      <th>Event gender</th>\n",
       "      <th>Medal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1924</td>\n",
       "      <td>Chamonix</td>\n",
       "      <td>Skating</td>\n",
       "      <td>Figure skating</td>\n",
       "      <td>AUT</td>\n",
       "      <td>individual</td>\n",
       "      <td>M</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1924</td>\n",
       "      <td>Chamonix</td>\n",
       "      <td>Skating</td>\n",
       "      <td>Figure skating</td>\n",
       "      <td>AUT</td>\n",
       "      <td>individual</td>\n",
       "      <td>W</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1924</td>\n",
       "      <td>Chamonix</td>\n",
       "      <td>Skating</td>\n",
       "      <td>Figure skating</td>\n",
       "      <td>AUT</td>\n",
       "      <td>pairs</td>\n",
       "      <td>X</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1924</td>\n",
       "      <td>Chamonix</td>\n",
       "      <td>Bobsleigh</td>\n",
       "      <td>Bobsleigh</td>\n",
       "      <td>BEL</td>\n",
       "      <td>four-man</td>\n",
       "      <td>M</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1924</td>\n",
       "      <td>Chamonix</td>\n",
       "      <td>Ice Hockey</td>\n",
       "      <td>Ice Hockey</td>\n",
       "      <td>CAN</td>\n",
       "      <td>ice hockey</td>\n",
       "      <td>M</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year      City       Sport      Discipline  NOC       Event Event gender  \\\n",
       "0  1924  Chamonix     Skating  Figure skating  AUT  individual            M   \n",
       "1  1924  Chamonix     Skating  Figure skating  AUT  individual            W   \n",
       "2  1924  Chamonix     Skating  Figure skating  AUT       pairs            X   \n",
       "3  1924  Chamonix   Bobsleigh       Bobsleigh  BEL    four-man            M   \n",
       "4  1924  Chamonix  Ice Hockey      Ice Hockey  CAN  ice hockey            M   \n",
       "\n",
       "    Medal  \n",
       "0  Silver  \n",
       "1    Gold  \n",
       "2    Gold  \n",
       "3  Bronze  \n",
       "4    Gold  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medals_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "greenhouse-bracelet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "driving-radical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server status: 200\n"
     ]
    }
   ],
   "source": [
    "http= urllib3.PoolManager()\n",
    "response= http.request('POST', medals_url)\n",
    "print('server status: '+str(response.status))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "black-applicant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_urllib= response.data\n",
    "type(df_urllib)\n",
    "\n",
    "#convertir variable byte a string\n",
    "df_url_string= df_urllib.decode('utf-8')\n",
    "df_url_string\n",
    "type(df_url_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-square",
   "metadata": {},
   "source": [
    "## Ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "taken-event",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convertir del string desordenado a una lista entendible, separando por salto de linea\n",
    "df_url_string_list= df_url_string.split(\"\\n\")\n",
    "#df_url_string_list\n",
    "\n",
    "\n",
    "df_dict= {}\n",
    "\n",
    "\n",
    "#sacar las columnas\n",
    "cols_list= df_url_string_list[0].split(\",\")\n",
    "cols_list\n",
    "for i in cols_list:\n",
    "    df_dict[i]= []\n",
    "#df_dict\n",
    "\n",
    "\n",
    "#eliminar los nombres de columnas de la lista\n",
    "df_url_string_list.pop(0)\n",
    "#df_url_string_list\n",
    "\n",
    "\n",
    "#sacar las filas\n",
    "rows_list= []\n",
    "for i in df_url_string_list:\n",
    "    rows_list.append(i.split(','))\n",
    "    \n",
    "rows_list\n",
    "    \n",
    "\n",
    "#armar el diccionario\n",
    "for i in range(len(cols_list)):\n",
    "    for j in rows_list:\n",
    "        df_dict[cols_list[i]].append(j[i])\n",
    "\n",
    "df_dict\n",
    "\n",
    "\n",
    "#pasar el diccionario a data frame\n",
    "df_dict_df= pd.DataFrame(df_dict)\n",
    "df_dict_df\n",
    "\n",
    "#guardar el df como csv\n",
    "df_dict_df.to_csv(mainpath+'ejercicio_medals_csv_export.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-ethics",
   "metadata": {},
   "source": [
    "# Ficheros .xls y .xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "medium-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_titanic_xls= 'titanic/titanic3.xls'\n",
    "filename_titanic_xlsx= 'titanic/titanic3.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "breathing-brother",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic2= pd.read_excel(mainpath+filename_titanic_xls, 'titanic3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "liable-generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic3= pd.read_excel(mainpath+filename_titanic_xlsx, 'titanic3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "increased-citizen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crear archivos csv, xls, json o xlsx a partir de los dataframes\n",
    "titanic3.to_csv(mainpath+'titanic/titanic_custom_csv.csv')\n",
    "titanic3.to_excel(mainpath+'titanic/titanic_custom_excel.xlsx')\n",
    "titanic3.to_json(mainpath+'titanic/titanic_custom_json.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-consolidation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
